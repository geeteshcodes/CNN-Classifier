{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4097,
     "status": "ok",
     "timestamp": 1727869696217,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1727869699295,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "FIleuCAjoFD8",
    "outputId": "9c409700-4a44-4ac5-b45a-374e448511a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1727869749266,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "SH4WzfOhpKc3",
    "outputId": "eefdf71b-6707-4ad0-99db-04603d820197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 2 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 2 classes.\n",
      "Using 1600 files for validation.\n",
      "Class names: ['cats', 'dogs']\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/training_set\",\n",
    "    image_size=(64,64),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42\n",
    ")\n",
    "#imagedatagenerator old api using image_dataset_from_directory beter and faster need to add argumentation seperately\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/training_set\",\n",
    "    image_size=(64,64),\n",
    "    batch_size=32,\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42\n",
    ")\n",
    "# ⚡️ Normalization (equivalent to rescale=1./255)\n",
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "\n",
    "# ⚡️ Augmentation layers (equivalent to shear, zoom, flip)\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    keras.layers.RandomRotation(0.2),  # kinda like shear\n",
    "])\n",
    "class_names = train_ds.class_names #to get class name before tf starts and get indices from subfolders\n",
    "\n",
    "print(\"Class names:\", class_names)\n",
    "# Apply normalization + augmentation\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(normalization_layer(x), training=True), y))\n",
    "val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1727869817668,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1727869820333,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "XPzPrMckl-hV",
    "outputId": "329e2f0a-ec6c-4b72-c6ad-000f7ba7cda6"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1727869823557,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1727869826266,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1727869828932,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1727869831487,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1727870028191,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1727870049309,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53294,
     "status": "ok",
     "timestamp": 1727870127564,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "XUj1W4PJptta",
    "outputId": "6af733bf-672f-4229-efe2-f0847b4118e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "200/200 [==============================] - 14s 40ms/step - loss: 0.6906 - accuracy: 0.5431 - val_loss: 0.6556 - val_accuracy: 0.6394\n",
      "Epoch 2/25\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.6623 - accuracy: 0.6131 - val_loss: 0.6321 - val_accuracy: 0.6538\n",
      "Epoch 3/25\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.6340 - accuracy: 0.6459 - val_loss: 0.6383 - val_accuracy: 0.6469\n",
      "Epoch 4/25\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.6037 - accuracy: 0.6697 - val_loss: 0.5536 - val_accuracy: 0.7169\n",
      "Epoch 5/25\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.5992 - accuracy: 0.6705 - val_loss: 0.5452 - val_accuracy: 0.7262\n",
      "Epoch 6/25\n",
      "200/200 [==============================] - 9s 42ms/step - loss: 0.5753 - accuracy: 0.6944 - val_loss: 0.5898 - val_accuracy: 0.6988\n",
      "Epoch 7/25\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.5687 - accuracy: 0.7014 - val_loss: 0.6590 - val_accuracy: 0.6531\n",
      "Epoch 8/25\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.5641 - accuracy: 0.7011 - val_loss: 0.5318 - val_accuracy: 0.7437\n",
      "Epoch 9/25\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.5469 - accuracy: 0.7156 - val_loss: 0.5114 - val_accuracy: 0.7475\n",
      "Epoch 10/25\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.5420 - accuracy: 0.7239 - val_loss: 0.5407 - val_accuracy: 0.7350\n",
      "Epoch 11/25\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.5359 - accuracy: 0.7233 - val_loss: 0.5845 - val_accuracy: 0.7119\n",
      "Epoch 12/25\n",
      "200/200 [==============================] - 10s 47ms/step - loss: 0.5304 - accuracy: 0.7308 - val_loss: 0.5170 - val_accuracy: 0.7556\n",
      "Epoch 13/25\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.5142 - accuracy: 0.7428 - val_loss: 0.5045 - val_accuracy: 0.7588\n",
      "Epoch 14/25\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.5138 - accuracy: 0.7405 - val_loss: 0.5191 - val_accuracy: 0.7600\n",
      "Epoch 15/25\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.5101 - accuracy: 0.7522 - val_loss: 0.5332 - val_accuracy: 0.7306\n",
      "Epoch 16/25\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.5014 - accuracy: 0.7513 - val_loss: 0.4983 - val_accuracy: 0.7688\n",
      "Epoch 17/25\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4882 - accuracy: 0.7634 - val_loss: 0.5001 - val_accuracy: 0.7513\n",
      "Epoch 18/25\n",
      "200/200 [==============================] - 9s 45ms/step - loss: 0.4871 - accuracy: 0.7630 - val_loss: 0.4955 - val_accuracy: 0.7725\n",
      "Epoch 19/25\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4839 - accuracy: 0.7655 - val_loss: 0.4954 - val_accuracy: 0.7619\n",
      "Epoch 20/25\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.4823 - accuracy: 0.7672 - val_loss: 0.5245 - val_accuracy: 0.7450\n",
      "Epoch 21/25\n",
      "200/200 [==============================] - 9s 42ms/step - loss: 0.4711 - accuracy: 0.7722 - val_loss: 0.4952 - val_accuracy: 0.7600\n",
      "Epoch 22/25\n",
      "200/200 [==============================] - 10s 49ms/step - loss: 0.4692 - accuracy: 0.7744 - val_loss: 0.5442 - val_accuracy: 0.7306\n",
      "Epoch 23/25\n",
      "200/200 [==============================] - 9s 44ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5418 - val_accuracy: 0.7437\n",
      "Epoch 24/25\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.4646 - accuracy: 0.7820 - val_loss: 0.4845 - val_accuracy: 0.7681\n",
      "Epoch 25/25\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.4579 - accuracy: 0.7819 - val_loss: 0.5064 - val_accuracy: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x275e36b9180>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = train_ds, validation_data = val_ds, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1727870175470,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "gsSiWEJY1BPB",
    "outputId": "3a1eabe0-aa2b-48ac-cc6e-a32906dbf08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prediction: dogs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "# Binary output → sigmoid activation, so we check probability > 0.5\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = class_names[1]  # 'dogs'\n",
    "else:\n",
    "    prediction = class_names[0]  # 'cats'\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1727870200094,
     "user": {
      "displayName": "Hadelin de Ponteves",
      "userId": "15047218817161520419"
     },
     "user_tz": -240
    },
    "id": "ED9KB3I54c1i",
    "outputId": "7f130fcb-f755-463d-c743-b9d3565b5e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2fBThgo8wJQn6Xf6V6crC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf-2.10)",
   "language": "python",
   "name": "tf-2.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
